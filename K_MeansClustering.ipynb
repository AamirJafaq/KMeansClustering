{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOWag0fONv8WYClKWzezKJn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AamirJafaq/KMeansClustering/blob/main/K_MeansClustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Means Clustering"
      ],
      "metadata": {
        "id": "eHFpGIgUO5wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-means clustering is an unsupervised learning algorithm used for data clustering, which groups unlabeled data points into groups or clusters. Among the different types of clustering algorithms such as exclusive, overlapping, hierarchical, and probabilistic, K-means is an example of an exclusive (or “hard”) clustering method. In this approach, each data point is assigned to exactly one cluster, meaning it cannot belong to multiple groups at the same time."
      ],
      "metadata": {
        "id": "2wYLCJztNdFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How does K-means work?"
      ],
      "metadata": {
        "id": "zxMHRjTowtyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The K-means clustering algorithm can be summarized in the following steps:\n",
        "1. Choose $k$ number of data points. These points will act as the initial cluster centroids.\n",
        "2. For each point, compute its distance to all K centroids and assign it to the cluster with the closest centroid. Repeating this procedure produces $k$ distinct clusters.\n",
        "3. Next, update the centroids by computing the mean of all data points assigned to each cluster.\n",
        "4. Repeat steps 2 and 3 until the centroids converge and the data point assignments remain unchanged."
      ],
      "metadata": {
        "id": "E6SxCsXjxOZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distance Metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "467m8hMB23a6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An important step in clustering is to select a distance metric, which will determine how the similarity of two elements is calculated. In K-Means Clustering, following distrance metrics can be used:\n",
        "* Euclidean Distance\n",
        "* Minkowski Distance\n",
        "* Manhattan Distance"
      ],
      "metadata": {
        "id": "LJlj-Rec29dq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Centroid Initialization Methods"
      ],
      "metadata": {
        "id": "ss4neVRy29lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positioning the initial centroids can be challenging, as the goal is to place them as close as possible to the true centroids’ optimal positions. Several methods for initializing centroids are described below:\\\n",
        "**Random Data Points:**"
      ],
      "metadata": {
        "id": "tt_I1VqL31-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dXTzXZjw32A9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7sDnLg-B32Dq"
      }
    }
  ]
}